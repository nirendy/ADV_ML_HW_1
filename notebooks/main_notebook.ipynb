{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "!pip install torch tensorboard torchtext datasets",
   "id": "130ebdce38d34215"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:11:59.745743Z",
     "start_time": "2024-07-12T17:11:58.885381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from src.datasets.mathqa_dataset import MathQADataset\n",
    "from src.datasets.retrieval_dataset import RetrievalDataset\n",
    "\n"
   ],
   "id": "12756a834b03ed33",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:11:59.749Z",
     "start_time": "2024-07-12T17:11:59.746513Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "3d8dfc9f08c9a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:12:00.571655Z",
     "start_time": "2024-07-12T17:11:59.749442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from config.try1 import config\n",
    "from src.utils.experiment_runner import run_experiment\n",
    "from src.datasets.listops_dataset import ListOpsDataset\n",
    "from src.models.lstm import LSTMArchitecture\n",
    "from src.models.transformer import TransformerArchitecture\n",
    "\n",
    "from src.models.s4 import S4Architecture\n",
    "\n",
    "architectures = [\n",
    "    LSTMArchitecture(config['lstm']),\n",
    "    TransformerArchitecture(config['transformer']),\n",
    "    S4Architecture(config['s4'])\n",
    "]\n",
    "pretrain_datasets = [None, MathQADataset, RetrievalDataset]\n",
    "finetune_datasets = [ListOpsDataset()]\n",
    "\n",
    "# Run the experiment and display the results\n",
    "results_df = run_experiment(architectures, pretrain_datasets, finetune_datasets)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nirendy/miniconda3/envs/ADV_ML_HW_1/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LSTMArchitecture' object has no attribute 'num_layers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m finetune_datasets \u001B[38;5;241m=\u001B[39m [ListOpsDataset()]\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Run the experiment and display the results\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m results_df \u001B[38;5;241m=\u001B[39m run_experiment(architectures, pretrain_datasets, finetune_datasets)\n",
      "File \u001B[0;32m~/school-repo/ADV_ML_HW_1/utils/experiment_runner.py:61\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(architectures, pretrain_datasets, finetune_datasets)\u001B[0m\n\u001B[1;32m     59\u001B[0m pretrain_name \u001B[38;5;241m=\u001B[39m pretrain_dataset\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pretrain_dataset \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     60\u001B[0m run_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchitecture\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrain_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfinetune_dataset\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 61\u001B[0m metrics \u001B[38;5;241m=\u001B[39m train_and_evaluate_model(architecture, pretrain_dataset, finetune_dataset, writer, run_id)\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Record results\u001B[39;00m\n\u001B[1;32m     64\u001B[0m result \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mArchitecture\u001B[39m\u001B[38;5;124m'\u001B[39m: architecture\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPretrain Dataset\u001B[39m\u001B[38;5;124m'\u001B[39m: pretrain_name,\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinetune Dataset\u001B[39m\u001B[38;5;124m'\u001B[39m: finetune_dataset\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,\n\u001B[1;32m     68\u001B[0m }\n",
      "File \u001B[0;32m~/school-repo/ADV_ML_HW_1/utils/experiment_runner.py:33\u001B[0m, in \u001B[0;36mtrain_and_evaluate_model\u001B[0;34m(architecture, pretrain_dataset, finetune_dataset, writer, run_id)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pretrain_loader:\n\u001B[1;32m     32\u001B[0m     architecture\u001B[38;5;241m.\u001B[39mtrain_model(pretrain_loader)\n\u001B[0;32m---> 33\u001B[0m architecture\u001B[38;5;241m.\u001B[39mtrain_model(finetune_loader)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Evaluate model\u001B[39;00m\n\u001B[1;32m     36\u001B[0m architecture\u001B[38;5;241m.\u001B[39mevaluate_model(test_loader)\n",
      "File \u001B[0;32m~/school-repo/ADV_ML_HW_1/models/lstm.py:56\u001B[0m, in \u001B[0;36mLSTMArchitecture.train_model\u001B[0;34m(self, train_loader)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, target \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 56\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(data)\n\u001B[1;32m     57\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(output, target)\n\u001B[1;32m     58\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/school-repo/ADV_ML_HW_1/models/lstm.py:71\u001B[0m, in \u001B[0;36mLSTMArchitecture.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 71\u001B[0m     h \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mzeros(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers)]\n\u001B[1;32m     72\u001B[0m     c \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mzeros(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdevice) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers)]\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m)):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LSTMArchitecture' object has no attribute 'num_layers'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(results_df)",
   "id": "98bceccf18d6fbb5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
