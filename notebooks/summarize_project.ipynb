{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T05:51:07.416128Z",
     "start_time": "2024-07-20T05:51:07.321893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast\n",
    "\n",
    "def get_type_annotation(arg):\n",
    "    if arg.annotation:\n",
    "        if isinstance(arg.annotation, ast.Name):\n",
    "            return arg.annotation.id\n",
    "        elif isinstance(arg.annotation, ast.Subscript):\n",
    "            value_id = arg.annotation.value.id if isinstance(arg.annotation.value, ast.Name) else None\n",
    "            slice_id = arg.annotation.slice.id if isinstance(arg.annotation.slice, ast.Name) else None\n",
    "            return (value_id, slice_id)\n",
    "    return None\n",
    "\n",
    "def add_parent_info(tree):\n",
    "    for node in ast.walk(tree):\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            child.parent = node\n",
    "\n",
    "def get_init_function_body(node):\n",
    "    for sub_node in node.body:\n",
    "        if isinstance(sub_node, ast.FunctionDef) and sub_node.name == \"__init__\":\n",
    "            return ast.unparse(sub_node)\n",
    "    return None\n",
    "\n",
    "def get_class_and_function_info(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    tree = ast.parse(file_content)\n",
    "    add_parent_info(tree)\n",
    "\n",
    "    class_info = {}\n",
    "    module_functions = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            class_name = node.name\n",
    "            methods = []\n",
    "            init_body = None\n",
    "            for sub_node in node.body:\n",
    "                if isinstance(sub_node, ast.FunctionDef):\n",
    "                    args = [(arg.arg, get_type_annotation(arg)) for arg in sub_node.args.args]\n",
    "                    methods.append({\n",
    "                        'name': sub_node.name,\n",
    "                        'args': args\n",
    "                    })\n",
    "                    if sub_node.name == \"__init__\":\n",
    "                        init_body = ast.unparse(sub_node)\n",
    "            class_info[class_name] = {\n",
    "                'methods': methods,\n",
    "                'init_body': init_body\n",
    "            }\n",
    "        elif isinstance(node, ast.FunctionDef) and isinstance(node.parent, ast.Module):\n",
    "            args = [(arg.arg, get_type_annotation(arg)) for arg in node.args.args]\n",
    "            module_functions.append({\n",
    "                'name': node.name,\n",
    "                'args': args\n",
    "            })\n",
    "\n",
    "    return class_info, module_functions\n",
    "\n",
    "def summarize_directory(directory):\n",
    "    summary = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                class_info, module_functions = get_class_and_function_info(filepath)\n",
    "                summary.append({\n",
    "                    'file': filepath,\n",
    "                    'classes': class_info,\n",
    "                    'functions': module_functions,\n",
    "                })\n",
    "    return summary\n",
    "\n",
    "def print_summary(summary):\n",
    "    for item in summary:\n",
    "        print(f\"File: {item['file']}\")\n",
    "        if item['classes']:\n",
    "            for class_name, class_details in item['classes'].items():\n",
    "                print(f\"  Class: {class_name}\")\n",
    "                for method in class_details['methods']:\n",
    "                    args = ', '.join([f\"{arg[0]}: {arg[1]}\" if arg[1] else arg[0] for arg in method['args']])\n",
    "                    print(f\"    - Method: {method['name']}({args})\")\n",
    "                if class_details['init_body']:\n",
    "                    print(f\"    - __init__ implementation:\\n{class_details['init_body']}\")\n",
    "        if item['functions']:\n",
    "            print(\"  Functions:\")\n",
    "            for function in item['functions']:\n",
    "                args = ', '.join([f\"{arg[0]}: {arg[1]}\" if arg[1] else arg[0] for arg in function['args']])\n",
    "                print(f\"    - {function['name']}({args})\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory = '.'  # Replace with your directory path\n",
    "    summary = summarize_directory(directory)\n",
    "    print_summary(summary)\n"
   ],
   "id": "8c7ba01f0fff8319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./main.py\n",
      "\n",
      "File: ./tests/test_datasets.py\n",
      "\n",
      "File: ./tests/__init__.py\n",
      "\n",
      "File: ./tests/test_experiment_runner.py\n",
      "\n",
      "File: ./tests/test_models.py\n",
      "\n",
      "File: ./tests/test_strategies.py\n",
      "\n",
      "File: ./scripts/preprocess_listops.py\n",
      "  Functions:\n",
      "    - build_vocab(file_path)\n",
      "    - preprocess_data(part, vocab, ch2idx, max_seq, input_file, output_data_file, output_target_file)\n",
      "\n",
      "File: ./src/__init__.py\n",
      "\n",
      "File: ./src/evaluate.py\n",
      "\n",
      "File: ./src/trainer.py\n",
      "  Class: Trainer\n",
      "    - Method: __init__(self, training_config: TrainingConfig)\n",
      "    - Method: get_loss_fn(self)\n",
      "    - Method: train_and_evaluate_model(self, architecture: Architecture, pretrain_dataset: ('Optional', 'BaseDataset'), finetune_dataset: BaseDataset, writer: SummaryWriter, run_id: str)\n",
      "    - Method: _train_model(self, architecture: Architecture, dataset: BaseDataset, writer: SummaryWriter, phase_name: str, device, run_id: str)\n",
      "    - Method: _evaluate_model(self, architecture: Architecture, dataset: BaseDataset)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, training_config: TrainingConfig):\n",
      "    self.training_config = training_config\n",
      "  Functions:\n",
      "    - set_seed(seed: int)\n",
      "\n",
      "File: ./src/datasets/mathqa_dataset.py\n",
      "  Class: MathQADataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./src/datasets/base_dataset.py\n",
      "  Class: BaseDataset\n",
      "    - Method: get_dataset(self, split: str)\n",
      "    - Method: vocab_size(self)\n",
      "    - Method: get_train_dataset(self)\n",
      "    - Method: get_test_dataset(self)\n",
      "    - Method: get_val_dataset(self)\n",
      "\n",
      "File: ./src/datasets/listops_dataset.py\n",
      "  Class: ListOpsDataset\n",
      "    - Method: data_dir(self)\n",
      "    - Method: vocab_size(self)\n",
      "    - Method: get_dataset(self, split: str)\n",
      "  Class: ListOpsTorchDataset\n",
      "    - Method: __init__(self, data, targets)\n",
      "    - Method: __len__(self)\n",
      "    - Method: __getitem__(self, idx)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, data, targets):\n",
      "    self.data = data\n",
      "    self.targets = targets\n",
      "\n",
      "File: ./src/datasets/__init__.py\n",
      "\n",
      "File: ./src/datasets/retrieval_dataset.py\n",
      "  Class: RetrievalDataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./src/utils/config_types.py\n",
      "  Class: LSTMConfig\n",
      "  Class: TransformerConfig\n",
      "  Class: S4Config\n",
      "  Class: TrainingConfig\n",
      "  Class: Config\n",
      "\n",
      "File: ./src/utils/metrics.py\n",
      "\n",
      "File: ./src/utils/experiment_runner.py\n",
      "  Functions:\n",
      "    - run_experiment(architectures: ('List', 'Architecture'), pretrain_datasets: ('List', None), finetune_datasets: ('List', 'BaseDataset'), trainer: Trainer, writer: SummaryWriter)\n",
      "    - load_config(config_name: str)\n",
      "    - init_experiment(config_name: str)\n",
      "\n",
      "File: ./src/utils/__init__.py\n",
      "\n",
      "File: ./src/models/s4.py\n",
      "  Class: S4Layer\n",
      "    - Method: __init__(self, d_model, state_size)\n",
      "    - Method: forward(self, x)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, d_model, state_size):\n",
      "    super(S4Layer, self).__init__()\n",
      "    self.d_model = d_model\n",
      "    self.state_size = state_size\n",
      "    self.W = nn.Parameter(torch.randn(d_model, state_size))\n",
      "    self.U = nn.Parameter(torch.randn(d_model, state_size))\n",
      "    self.V = nn.Parameter(torch.randn(state_size, d_model))\n",
      "  Class: S4Architecture\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "\n",
      "File: ./src/models/__init__.py\n",
      "\n",
      "File: ./src/models/transformer.py\n",
      "  Class: TransformerEncoderLayer\n",
      "    - Method: __init__(self, d_model, nhead, dim_feedforward, dropout)\n",
      "    - Method: forward(self, src)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
      "    super(TransformerEncoderLayer, self).__init__()\n",
      "    self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
      "    self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
      "    self.dropout = nn.Dropout(dropout)\n",
      "    self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
      "    self.norm1 = nn.LayerNorm(d_model)\n",
      "    self.norm2 = nn.LayerNorm(d_model)\n",
      "    self.dropout1 = nn.Dropout(dropout)\n",
      "    self.dropout2 = nn.Dropout(dropout)\n",
      "  Class: TransformerArchitecture\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "\n",
      "File: ./src/models/architecture.py\n",
      "  Class: Architecture\n",
      "    - Method: __init__(self, config: ('Dict', None))\n",
      "    - Method: initialize_model(self, dataset: BaseDataset)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: save_model(self, path: str)\n",
      "    - Method: load_model(self, path: str)\n",
      "    - Method: predict(self, data: Any)\n",
      "    - Method: configure_logging(self, log_level: int)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, config: Dict[str, Any]):\n",
      "    super(Architecture, self).__init__()\n",
      "    self.model_config = config\n",
      "    self.logger = logging.getLogger(self.__class__.__name__)\n",
      "    self.logger.setLevel(logging.INFO)\n",
      "\n",
      "File: ./src/models/lstm.py\n",
      "  Class: LSTMCell\n",
      "    - Method: __init__(self, input_size, hidden_size)\n",
      "    - Method: forward(self, x, hidden)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, input_size, hidden_size):\n",
      "    super(LSTMCell, self).__init__()\n",
      "    self.input_size = input_size\n",
      "    self.hidden_size = hidden_size\n",
      "    self.i2h = nn.Linear(input_size, 4 * hidden_size)\n",
      "    self.h2h = nn.Linear(hidden_size, 4 * hidden_size)\n",
      "  Class: LSTMLayer\n",
      "    - Method: __init__(self, input_size, hidden_size, num_layers)\n",
      "    - Method: forward(self, x, hidden)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, input_size, hidden_size, num_layers):\n",
      "    super(LSTMLayer, self).__init__()\n",
      "    self.num_layers = num_layers\n",
      "    self.hidden_size = hidden_size\n",
      "    self.cells = nn.ModuleList()\n",
      "    for i in range(num_layers):\n",
      "        self.cells.append(LSTMCell(input_size if i == 0 else hidden_size, hidden_size))\n",
      "  Class: LSTMArchitecture\n",
      "    - Method: __init__(self, model_config: LSTMConfig)\n",
      "    - Method: initialize_model(self, dataset: BaseDataset)\n",
      "    - Method: forward(self, x)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, model_config: LSTMConfig):\n",
      "    super(LSTMArchitecture, self).__init__(model_config)\n",
      "\n",
      "File: ./src/configs/try1.py\n",
      "\n",
      "File: ./src/configs/__init__.py\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d42f78bde72fc0ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
