{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:18:38.135640Z",
     "start_time": "2024-07-11T20:18:38.103118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast"
   ],
   "id": "f245bf48465d129b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:19:21.020239Z",
     "start_time": "2024-07-11T20:19:21.011452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_type_annotation(arg):\n",
    "    if arg.annotation:\n",
    "        if isinstance(arg.annotation, ast.Name):\n",
    "            return arg.annotation.id\n",
    "        elif isinstance(arg.annotation, ast.Subscript):\n",
    "            value_id = arg.annotation.value.id if isinstance(arg.annotation.value, ast.Name) else None\n",
    "            slice_id = arg.annotation.slice.id if isinstance(arg.annotation.slice, ast.Name) else None\n",
    "            return (value_id, slice_id)\n",
    "    return None\n",
    "\n",
    "def add_parent_info(tree):\n",
    "    for node in ast.walk(tree):\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            child.parent = node\n",
    "\n",
    "def get_class_and_function_info(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    tree = ast.parse(file_content)\n",
    "    add_parent_info(tree)\n",
    "\n",
    "    class_info = {}\n",
    "    module_functions = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            class_name = node.name\n",
    "            methods = []\n",
    "            for sub_node in node.body:\n",
    "                if isinstance(sub_node, ast.FunctionDef):\n",
    "                    args = [(arg.arg, get_type_annotation(arg)) for arg in sub_node.args.args]\n",
    "                    methods.append({\n",
    "                        'name': sub_node.name,\n",
    "                        'args': args\n",
    "                    })\n",
    "            class_info[class_name] = methods\n",
    "        elif isinstance(node, ast.FunctionDef) and isinstance(node.parent, ast.Module):\n",
    "            args = [(arg.arg, get_type_annotation(arg)) for arg in node.args.args]\n",
    "            module_functions.append({\n",
    "                'name': node.name,\n",
    "                'args': args\n",
    "            })\n",
    "\n",
    "    return class_info, module_functions\n",
    "\n",
    "def summarize_directory(directory):\n",
    "    summary = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                class_info, module_functions = get_class_and_function_info(filepath)\n",
    "                summary.append({\n",
    "                    'file': filepath,\n",
    "                    'classes': class_info,\n",
    "                    'functions': module_functions,\n",
    "                })\n",
    "    return summary\n",
    "\n",
    "def print_summary(summary):\n",
    "    for item in summary:\n",
    "        print(f\"File: {item['file']}\")\n",
    "        if item['classes']:\n",
    "            for class_name, methods in item['classes'].items():\n",
    "                print(f\"  Class: {class_name}\")\n",
    "                for method in methods:\n",
    "                    args = ', '.join([f\"{arg[0]}: {arg[1]}\" if arg[1] else arg[0] for arg in method['args']])\n",
    "                    print(f\"    - Method: {method['name']}({args})\")\n",
    "        if item['functions']:\n",
    "            print(\"  Functions:\")\n",
    "            for function in item['functions']:\n",
    "                args = ', '.join([f\"{arg[0]}: {arg[1]}\" if arg[1] else arg[0] for arg in function['args']])\n",
    "                print(f\"    - {function['name']}({args})\")\n",
    "        print()\n"
   ],
   "id": "7a33bb1732ef7ee7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:19:21.682459Z",
     "start_time": "2024-07-11T20:19:21.659320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory = '.'  # Replace with your directory path\n",
    "summary = summarize_directory(directory)\n",
    "print_summary(summary)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./main.py\n",
      "\n",
      "File: ./datasets/mathqa_dataset.py\n",
      "  Class: MathQADataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./datasets/base_dataset.py\n",
      "  Class: Dataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./datasets/listops_dataset.py\n",
      "  Class: ListOpsDataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./datasets/__init__.py\n",
      "\n",
      "File: ./datasets/retrieval_dataset.py\n",
      "  Class: RetrievalDataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./tests/test_datasets.py\n",
      "\n",
      "File: ./tests/__init__.py\n",
      "\n",
      "File: ./tests/test_experiment_runner.py\n",
      "\n",
      "File: ./tests/test_models.py\n",
      "\n",
      "File: ./tests/test_strategies.py\n",
      "\n",
      "File: ./utils/metrics.py\n",
      "\n",
      "File: ./utils/experiment_runner.py\n",
      "  Functions:\n",
      "    - train_and_evaluate_model(architecture: Architecture, pretrain_dataset: ('Optional', 'Dataset'), finetune_dataset: Dataset, writer: SummaryWriter, run_id: str)\n",
      "    - run_experiment(architectures: ('List', 'Architecture'), pretrain_datasets: ('List', None), finetune_datasets: ('List', 'Dataset'))\n",
      "\n",
      "File: ./utils/__init__.py\n",
      "\n",
      "File: ./models/s4.py\n",
      "  Class: S4Layer\n",
      "    - Method: __init__(self, d_model, state_size)\n",
      "    - Method: forward(self, x)\n",
      "  Class: S4Architecture\n",
      "    - Method: __init__(self)\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: get_metrics(self)\n",
      "\n",
      "File: ./models/__init__.py\n",
      "\n",
      "File: ./models/transformer.py\n",
      "  Class: TransformerEncoderLayer\n",
      "    - Method: __init__(self, d_model, nhead, dim_feedforward, dropout)\n",
      "    - Method: forward(self, src)\n",
      "  Class: TransformerArchitecture\n",
      "    - Method: __init__(self)\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: get_metrics(self)\n",
      "\n",
      "File: ./models/architecture.py\n",
      "  Class: Architecture\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: get_metrics(self)\n",
      "\n",
      "File: ./models/lstm.py\n",
      "  Class: LSTMCell\n",
      "    - Method: __init__(self, input_size, hidden_size)\n",
      "    - Method: forward(self, x, hidden)\n",
      "  Class: LSTMArchitecture\n",
      "    - Method: __init__(self)\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: get_metrics(self)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T20:31:46.269605Z",
     "start_time": "2024-07-11T20:31:46.223972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import ast\n",
    "\n",
    "def get_type_annotation(arg):\n",
    "    if arg.annotation:\n",
    "        if isinstance(arg.annotation, ast.Name):\n",
    "            return arg.annotation.id\n",
    "        elif isinstance(arg.annotation, ast.Subscript):\n",
    "            value_id = arg.annotation.value.id if isinstance(arg.annotation.value, ast.Name) else None\n",
    "            slice_id = arg.annotation.slice.id if isinstance(arg.annotation.slice, ast.Name) else None\n",
    "            return (value_id, slice_id)\n",
    "    return None\n",
    "\n",
    "def add_parent_info(tree):\n",
    "    for node in ast.walk(tree):\n",
    "        for child in ast.iter_child_nodes(node):\n",
    "            child.parent = node\n",
    "\n",
    "def get_init_function_body(node):\n",
    "    for sub_node in node.body:\n",
    "        if isinstance(sub_node, ast.FunctionDef) and sub_node.name == \"__init__\":\n",
    "            return ast.unparse(sub_node)\n",
    "    return None\n",
    "\n",
    "def get_class_and_function_info(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    tree = ast.parse(file_content)\n",
    "    add_parent_info(tree)\n",
    "\n",
    "    class_info = {}\n",
    "    module_functions = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.ClassDef):\n",
    "            class_name = node.name\n",
    "            methods = []\n",
    "            init_body = None\n",
    "            for sub_node in node.body:\n",
    "                if isinstance(sub_node, ast.FunctionDef):\n",
    "                    args = [(arg.arg, get_type_annotation(arg)) for arg in sub_node.args.args]\n",
    "                    methods.append({\n",
    "                        'name': sub_node.name,\n",
    "                        'args': args\n",
    "                    })\n",
    "                    if sub_node.name == \"__init__\":\n",
    "                        init_body = ast.unparse(sub_node)\n",
    "            class_info[class_name] = {\n",
    "                'methods': methods,\n",
    "                'init_body': init_body\n",
    "            }\n",
    "        elif isinstance(node, ast.FunctionDef) and isinstance(node.parent, ast.Module):\n",
    "            args = [(arg.arg, get_type_annotation(arg)) for arg in node.args.args]\n",
    "            module_functions.append({\n",
    "                'name': node.name,\n",
    "                'args': args\n",
    "            })\n",
    "\n",
    "    return class_info, module_functions\n",
    "\n",
    "def summarize_directory(directory):\n",
    "    summary = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                class_info, module_functions = get_class_and_function_info(filepath)\n",
    "                summary.append({\n",
    "                    'file': filepath,\n",
    "                    'classes': class_info,\n",
    "                    'functions': module_functions,\n",
    "                })\n",
    "    return summary\n",
    "\n",
    "def print_summary(summary):\n",
    "    for item in summary:\n",
    "        print(f\"File: {item['file']}\")\n",
    "        if item['classes']:\n",
    "            for class_name, class_details in item['classes'].items():\n",
    "                print(f\"  Class: {class_name}\")\n",
    "                for method in class_details['methods']:\n",
    "                    args = ', '.join([f\"{arg[0]}: {arg[1]}\" if arg[1] else arg[0] for arg in method['args']])\n",
    "                    print(f\"    - Method: {method['name']}({args})\")\n",
    "                if class_details['init_body']:\n",
    "                    print(f\"    - __init__ implementation:\\n{class_details['init_body']}\")\n",
    "        if item['functions']:\n",
    "            print(\"  Functions:\")\n",
    "            for function in item['functions']:\n",
    "                args = ', '.join([f\"{arg[0]}: {arg[1]}\" if arg[1] else arg[0] for arg in function['args']])\n",
    "                print(f\"    - {function['name']}({args})\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    directory = '.'  # Replace with your directory path\n",
    "    summary = summarize_directory(directory)\n",
    "    print_summary(summary)\n"
   ],
   "id": "8c7ba01f0fff8319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./main.py\n",
      "\n",
      "File: ./datasets/mathqa_dataset.py\n",
      "  Class: MathQADataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./datasets/base_dataset.py\n",
      "  Class: Dataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./datasets/listops_dataset.py\n",
      "  Class: ListOpsDataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./datasets/__init__.py\n",
      "\n",
      "File: ./datasets/retrieval_dataset.py\n",
      "  Class: RetrievalDataset\n",
      "    - Method: load_data(self)\n",
      "    - Method: get_train_loader(self)\n",
      "    - Method: get_test_loader(self)\n",
      "\n",
      "File: ./tests/test_datasets.py\n",
      "\n",
      "File: ./tests/__init__.py\n",
      "\n",
      "File: ./tests/test_experiment_runner.py\n",
      "\n",
      "File: ./tests/test_models.py\n",
      "\n",
      "File: ./tests/test_strategies.py\n",
      "\n",
      "File: ./utils/metrics.py\n",
      "\n",
      "File: ./utils/experiment_runner.py\n",
      "  Functions:\n",
      "    - train_and_evaluate_model(architecture: Architecture, pretrain_dataset: ('Optional', 'Dataset'), finetune_dataset: Dataset, writer: SummaryWriter, run_id: str)\n",
      "    - run_experiment(architectures: ('List', 'Architecture'), pretrain_datasets: ('List', None), finetune_datasets: ('List', 'Dataset'))\n",
      "\n",
      "File: ./utils/__init__.py\n",
      "\n",
      "File: ./models/s4.py\n",
      "  Class: S4Layer\n",
      "    - Method: __init__(self, d_model, state_size)\n",
      "    - Method: forward(self, x)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, d_model, state_size):\n",
      "    super(S4Layer, self).__init__()\n",
      "    self.d_model = d_model\n",
      "    self.state_size = state_size\n",
      "    self.W = nn.Parameter(torch.randn(d_model, state_size))\n",
      "    self.U = nn.Parameter(torch.randn(d_model, state_size))\n",
      "    self.V = nn.Parameter(torch.randn(state_size, d_model))\n",
      "  Class: S4Architecture\n",
      "    - Method: __init__(self)\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: get_metrics(self)\n",
      "    - __init__ implementation:\n",
      "def __init__(self):\n",
      "    self.d_model = 512\n",
      "    self.state_size = 256\n",
      "    self.num_layers = 3\n",
      "\n",
      "File: ./models/__init__.py\n",
      "\n",
      "File: ./models/transformer.py\n",
      "  Class: TransformerEncoderLayer\n",
      "    - Method: __init__(self, d_model, nhead, dim_feedforward, dropout)\n",
      "    - Method: forward(self, src)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
      "    super(TransformerEncoderLayer, self).__init__()\n",
      "    self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
      "    self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
      "    self.dropout = nn.Dropout(dropout)\n",
      "    self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
      "    self.norm1 = nn.LayerNorm(d_model)\n",
      "    self.norm2 = nn.LayerNorm(d_model)\n",
      "    self.dropout1 = nn.Dropout(dropout)\n",
      "    self.dropout2 = nn.Dropout(dropout)\n",
      "  Class: TransformerArchitecture\n",
      "    - Method: __init__(self)\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: get_metrics(self)\n",
      "    - __init__ implementation:\n",
      "def __init__(self):\n",
      "    self.d_model = 512\n",
      "    self.nhead = 8\n",
      "    self.num_layers = 6\n",
      "    self.dim_feedforward = 2048\n",
      "    self.dropout = 0.1\n",
      "\n",
      "File: ./models/architecture.py\n",
      "  Class: Architecture\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: get_metrics(self)\n",
      "\n",
      "File: ./models/lstm.py\n",
      "  Class: LSTMCell\n",
      "    - Method: __init__(self, input_size, hidden_size)\n",
      "    - Method: forward(self, x, hidden)\n",
      "    - __init__ implementation:\n",
      "def __init__(self, input_size, hidden_size):\n",
      "    super(LSTMCell, self).__init__()\n",
      "    self.input_size = input_size\n",
      "    self.hidden_size = hidden_size\n",
      "    self.i2h = nn.Linear(input_size + hidden_size, 4 * hidden_size)\n",
      "  Class: LSTMArchitecture\n",
      "    - Method: __init__(self)\n",
      "    - Method: initialize_model(self)\n",
      "    - Method: parameters(self)\n",
      "    - Method: train_model(self, train_loader)\n",
      "    - Method: evaluate_model(self, test_loader)\n",
      "    - Method: forward(self, x)\n",
      "    - Method: get_metrics(self)\n",
      "    - __init__ implementation:\n",
      "def __init__(self):\n",
      "    self.hidden_size = 20\n",
      "    self.input_size = 10\n",
      "    self.num_layers = 2\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aea5525ae4f6477a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
